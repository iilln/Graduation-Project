# Graduation-Project
Content filtering is a significant challenge in the field of Natural Language Processing (NLP). The rise of social media has led to an increase in harmful content, raising concerns among parents about their children's exposure to inappropriate materials. Therefore, effective filtering mechanisms are essential for creating a safer digital environment.

In our project, we developed a machine-learning model to analyze and detect harmful content on social media platforms. We collected 11,028 Arabic texts and 132,621 English texts, followed by data cleaning to ensure quality. We utilized the Support Vector Machine (SVM) algorithm to train the model and tested it on separate datasets in both Arabic and English to evaluate its accuracy.

The results showed a high accuracy in classifying Arabic texts, with an accuracy rate of 0.70, while the English dataset achieved an accuracy of 0.48. This reflects the model's effectiveness in identifying harmful content such as hate speech and abusive language. Our goal is to create a model that outperforms existing solutions, ultimately enhancing online safety for users.
